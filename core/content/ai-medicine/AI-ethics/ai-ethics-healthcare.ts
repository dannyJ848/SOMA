import { EducationalContent } from '../../types';

export const AI_ETHICS_HEALTHCARE: EducationalContent = {
  id: 'ai-ethics-healthcare',
  type: 'concept',
  name: 'AI Ethics in Healthcare',
  alternateNames: ['Medical AI Ethics', 'Healthcare AI Governance', 'Ethical AI in Medicine', 'AI Bioethics'],
  levels: {
    1: {
      level: 1,
      summary: 'AI ethics in healthcare is about making sure that computer programs used in medicine are fair, safe, and respect patients.',
      explanation: 'Artificial intelligence (AI) is being used more and more in healthcare to help doctors make decisions, read X-rays, and even predict who might get sick. But using AI in medicine raises important questions about what is right and fair. AI ethics in healthcare means thinking carefully about these questions. For example: Is the AI treating everyone fairly, or does it work better for some groups than others? Who is responsible if the AI makes a mistake? Can patients understand how the AI is being used in their care? Is patient information being kept private? These are the kinds of questions that doctors, computer scientists, and ethicists work on together to make sure AI helps patients without causing harm or being unfair.',
      keyTerms: [
        { term: 'artificial intelligence', definition: 'Computer systems that can perform tasks that typically require human intelligence' },
        { term: 'fairness', definition: 'Making sure the AI treats everyone equally and does not favor some groups over others' },
        { term: 'safety', definition: 'Ensuring the AI does not cause harm to patients' },
        { term: 'privacy', definition: 'Protecting personal health information from being shared without permission' },
        { term: 'responsibility', definition: 'Determining who is accountable when something goes wrong with AI decisions' },
      ],
    },
    2: {
      level: 2,
      summary: 'AI ethics in healthcare addresses principles of fairness, transparency, accountability, and privacy as artificial intelligence systems increasingly influence clinical decisions and patient care.',
      explanation: 'As artificial intelligence becomes integrated into healthcare, ethical frameworks help ensure these powerful tools serve patients well. Key ethical principles include beneficence (AI should help patients), non-maleficence (AI should not cause harm), autonomy (patients should understand and consent to AI use in their care), and justice (AI benefits and risks should be fairly distributed). Practical concerns include algorithmic bias, where AI systems may perform differently across demographic groups due to biased training data; transparency, ensuring clinicians understand how AI reaches its recommendations; accountability, determining responsibility when AI-influenced decisions lead to adverse outcomes; and privacy, protecting sensitive health information used to train and run AI systems. Regulatory bodies like the FDA are developing frameworks for AI medical devices, while professional organizations create guidelines for responsible AI use. Healthcare organizations must balance innovation potential against ethical obligations, implementing AI thoughtfully with appropriate oversight, monitoring, and safeguards.',
      keyTerms: [
        { term: 'algorithmic bias', definition: 'When AI systems perform differently for different groups of people due to flaws in data or design' },
        { term: 'transparency', definition: 'The ability to understand how AI systems work and make decisions' },
        { term: 'accountability', definition: 'The responsibility for AI system outcomes and the ability to explain decisions' },
        { term: 'informed consent', definition: 'Patients understanding and agreeing to AI use in their care' },
        { term: 'FDA regulation', definition: 'Government oversight of AI medical devices to ensure safety and effectiveness' },
        { term: 'beneficence', definition: 'The ethical principle that AI should benefit patients' },
        { term: 'non-maleficence', definition: 'The ethical principle that AI should not harm patients' },
      ],
    },
    3: {
      level: 3,
      summary: 'Healthcare AI ethics encompasses normative frameworks addressing algorithmic fairness, explainability, clinical accountability, data governance, and the evolving relationship between human clinicians and AI decision support systems.',
      explanation: 'Ethical analysis of healthcare AI draws upon biomedical ethics principles while addressing challenges unique to algorithmic systems. Fairness considerations examine both technical metrics (equalized odds, demographic parity, calibration across subgroups) and substantive justice concerns about which populations benefit from AI development and deployment. Explainability requirements vary by clinical context: high-stakes decisions may demand interpretable models or robust explanation methods, while lower-risk applications may tolerate opacity with appropriate validation. The accountability landscape involves multiple stakeholders: algorithm developers, healthcare organizations deploying systems, clinicians using AI outputs, and regulators overseeing safety and efficacy. Data governance frameworks must address consent for data use in AI development, re-identification risks in de-identified datasets, and ongoing obligations to individuals whose data trains systems. The human-AI relationship raises questions about appropriate clinician reliance on algorithmic recommendations, skill preservation when AI handles routine tasks, and maintaining meaningful human oversight. Professional guidelines from organizations including the AMA, WHO, and specialty societies provide frameworks for responsible implementation, while academic discourse continues refining ethical principles for this rapidly evolving field.',
      keyTerms: [
        { term: 'algorithmic fairness', definition: 'Technical and ethical approaches to ensure AI systems treat different groups equitably' },
        { term: 'explainability', definition: 'The ability to provide understandable explanations for AI predictions and recommendations' },
        { term: 'data governance', definition: 'Policies and practices for managing health data used in AI systems' },
        { term: 'human-AI interaction', definition: 'How clinicians and patients engage with and respond to AI systems' },
        { term: 'clinical accountability', definition: 'The responsibility framework for AI-influenced medical decisions' },
        { term: 'equalized odds', definition: 'A fairness metric requiring equal true positive and false positive rates across groups' },
        { term: 'interpretable models', definition: 'AI models whose decision-making process can be understood by humans' },
      ],
    },
    4: {
      level: 4,
      summary: 'The ethics of healthcare AI requires interdisciplinary engagement with algorithmic justice, epistemic authority, professional transformation, and governance mechanisms operating across development, deployment, and monitoring phases.',
      explanation: 'Scholarly examination of healthcare AI ethics spans philosophy, law, social science, and computer science perspectives. Algorithmic justice analysis extends beyond technical fairness metrics to examine structural inequities potentially encoded in training data, the political economy of AI development, and distributional consequences of AI deployment across healthcare systems. Epistemic considerations examine how AI reshapes clinical knowledge production and authority: questions arise about appropriate integration of algorithmic predictions with clinical expertise, the nature of machine-generated evidence, and implications for medical epistemology. Professional transformation concerns address how AI may restructure clinical work, potentially deskilling some tasks while creating new demands for AI oversight and interpretation capabilities. Governance frameworks operate across multiple levels: organizational policies for AI procurement and monitoring, professional guidelines for appropriate use, regulatory mechanisms for safety and efficacy, and emerging legal frameworks addressing liability and rights. Anticipatory ethics methodologies help identify potential harms before deployment, while ongoing monitoring systems detect emerging issues in production environments. Global perspectives reveal varying approaches to AI governance across jurisdictions, with implications for cross-border AI deployment and international standards development. Critical perspectives question whether current ethical frameworks adequately address power asymmetries in AI development and the potential for AI to exacerbate rather than reduce health inequities.',
      keyTerms: [
        { term: 'algorithmic justice', definition: 'Examining how AI systems may perpetuate or address structural inequities in healthcare' },
        { term: 'epistemic authority', definition: 'The legitimacy and trustworthiness of AI-generated knowledge in clinical settings' },
        { term: 'professional transformation', definition: 'How AI reshapes the roles, skills, and responsibilities of healthcare professionals' },
        { term: 'anticipatory ethics', definition: 'Proactive identification of potential harms before AI deployment' },
        { term: 'governance frameworks', definition: 'Multi-level structures for overseeing AI development and use in healthcare' },
        { term: 'structural inequity', definition: 'Systemic disadvantages built into social systems that may be encoded in AI training data' },
        { term: 'medical epistemology', definition: 'The study of how medical knowledge is produced, validated, and applied' },
      ],
    },
    5: {
      level: 5,
      summary: 'Clinical and institutional leadership in AI ethics requires practical implementation of ethical frameworks through governance structures, assessment processes, monitoring systems, and continuous engagement with evolving normative standards.',
      explanation: 'Translating AI ethics principles into healthcare practice demands systematic approaches across organizational, clinical, and technical domains. Governance structures should include ethics committees or AI oversight bodies with diverse expertise (clinical, technical, ethical, legal, patient perspectives) empowered to review AI implementations and address emerging concerns. Assessment processes for AI systems should examine clinical validity, fairness across patient populations, explainability appropriate to clinical context, data governance compliance, and integration with clinical workflows. Procurement practices should require vendor transparency about training data, validation studies, known limitations, and monitoring capabilities. Implementation protocols should address clinician training, informed consent processes, documentation requirements, and escalation pathways for AI-related concerns. Monitoring systems should track AI performance across demographic groups, detecting degradation or emergent biases requiring intervention. Patient engagement approaches should enable meaningful understanding and choice regarding AI use in their care, respecting autonomy while avoiding undue burden. Institutional culture should support reporting of AI-related concerns without fear of reprisal, enabling continuous improvement. Leaders must navigate tensions between innovation pressure and ethical obligations, ensuring AI adoption serves patients and populations rather than purely organizational or commercial interests. Engagement with evolving regulatory requirements, professional guidelines, and community standards should inform ongoing policy development.',
      keyTerms: [
        { term: 'AI governance', definition: 'Organizational structures and processes for overseeing AI implementation' },
        { term: 'ethics committee', definition: 'Body responsible for reviewing ethical implications of AI use in healthcare' },
        { term: 'assessment processes', definition: 'Systematic evaluation of AI systems for safety, fairness, and effectiveness' },
        { term: 'monitoring systems', definition: 'Ongoing surveillance of AI performance across patient populations' },
        { term: 'informed consent', definition: 'Process ensuring patients understand and agree to AI involvement in their care' },
        { term: 'institutional culture', definition: 'Organizational values and practices that shape AI implementation' },
        { term: 'regulatory engagement', definition: 'Interaction with government agencies overseeing AI in healthcare' },
        { term: 'patient engagement', definition: 'Involving patients in decisions about AI use in their care' },
      ],
      clinicalNotes: 'When using AI tools in clinical practice, understand the system\'s intended use, known limitations, and performance across different patient populations. Maintain appropriate skepticism of AI recommendations, applying clinical judgment to individual patient contexts. Communicate transparently with patients about AI involvement in their care. Document AI-influenced decisions appropriately. Report unexpected AI behaviors or concerning patterns to designated oversight bodies. Participate in ongoing education about AI capabilities and limitations as the field evolves.',
    },
  },
  media: [],
  citations: [
    { id: 'char-2018', type: 'article', title: 'Implementing Machine Learning in Health Care â€” Addressing Ethical Challenges', source: 'N Engl J Med. 2018;378(11):981-983' },
    { id: 'who-2021', type: 'article', title: 'Ethics and Governance of Artificial Intelligence for Health', source: 'World Health Organization. 2021' },
    { id: 'ama-2019', type: 'article', title: 'Augmented Intelligence in Health Care. Policy H-480.940', source: 'American Medical Association. 2019' },
    { id: 'obermeyer-2019', type: 'article', title: 'Dissecting racial bias in an algorithm used to manage the health of populations', source: 'Science. 2019;366(6464):447-453' },
  ],
  crossReferences: [
    { targetId: 'algorithmic-bias', targetType: 'concept', relationship: 'related', label: 'Algorithmic Bias' },
    { targetId: 'ai-transparency', targetType: 'concept', relationship: 'related', label: 'AI Transparency' },
    { targetId: 'health-data-privacy', targetType: 'concept', relationship: 'related', label: 'Health Data Privacy' },
    { targetId: 'prescription-digital-therapeutics', targetType: 'concept', relationship: 'related', label: 'Prescription Digital Therapeutics' },
  ],
  tags: {
    systems: ['digital-health'],
    topics: ['AI-ethics', 'healthcare-AI', 'algorithmic-fairness', 'medical-ethics', 'governance'],
    keywords: ['AI ethics', 'machine learning', 'fairness', 'accountability', 'transparency', 'bias', 'regulation'],
  },
  createdAt: '2025-01-28T00:00:00.000Z',
  updatedAt: '2025-01-28T00:00:00.000Z',
  version: 1,
  status: 'published',
  contributors: ['Biological Self Content Team'],
};
